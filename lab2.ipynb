{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lab2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 2\n",
    "### 3.1 Batch mode training using least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'lab2' has no attribute 'delta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [166]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mones(N)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m## Sine function\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#w = lab2.least_squares(x_train,yf1_train,mu,sigma)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[43mlab2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelta\u001b[49m(x_train,yf1_train,mu,sigma,\u001b[38;5;241m0.01\u001b[39m,\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     18\u001b[0m yf1_pred \u001b[38;5;241m=\u001b[39m lab2\u001b[38;5;241m.\u001b[39mforward(x_valid,w,mu,sigma)\n\u001b[0;32m     19\u001b[0m mse1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((yf1_pred\u001b[38;5;241m-\u001b[39myf1_valid)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'lab2' has no attribute 'delta'"
     ]
    }
   ],
   "source": [
    "## Generating data\n",
    "N = round(2*np.pi/0.1)\n",
    "x_train = np.linspace(0, 2*np.pi,N)\n",
    "yf1_train = np.sin(2*x_train)\n",
    "yf2_train = np.sign(yf1_train)\n",
    "x_valid = np.linspace(0.05, 2*np.pi,N)\n",
    "yf1_valid = np.sin(2*x_valid)\n",
    "yf2_valid = np.sign(yf1_valid)\n",
    "\n",
    "## Place RBF's manually\n",
    "N = 30 #Number of RBF's\n",
    "mu = np.linspace(0,2*np.pi,N) # Data is one-dimensional\n",
    "sigma = 0.1*np.ones(N)\n",
    "\n",
    "## Sine function\n",
    "#w = lab2.least_squares(x_train,yf1_train,mu,sigma)\n",
    "w = lab2.delta_rule(x_train,yf1_train,mu,sigma,0.01,100)\n",
    "yf1_pred = lab2.forward(x_valid,w,mu,sigma)\n",
    "mse1 = np.mean((yf1_pred-yf1_valid)**2)\n",
    "print('MSE sin(2x): ' + str(mse1))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(visible = True)\n",
    "ax.set_title('sin(2x)')\n",
    "ax.plot(x_valid,yf1_pred)\n",
    "ax.plot(x_valid,yf1_valid)\n",
    "plt.show()\n",
    "\n",
    "## Square function\n",
    "w = lab2.least_squares(x_train,yf2_train,mu,sigma)\n",
    "yf2_pred = lab2.forward(x_valid,w,mu,sigma)\n",
    "mse2 = np.mean((yf2_pred-yf2_valid)**2)\n",
    "print('MSE square(2x): ' + str(mse2))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(visible = True)\n",
    "ax.set_title('square(2x)')\n",
    "ax.plot(x_valid,yf2_pred)\n",
    "ax.plot(x_valid,yf2_valid)\n",
    "plt.show()\n",
    "\n",
    "## Varying to number of units to get below absolute residual error of 0.1, 0.01, 0.001\n",
    "maxN = 67\n",
    "are_sin = np.zeros(maxN-1)\n",
    "are_square = np.zeros(maxN-1)\n",
    "for i in np.linspace(2,maxN,maxN-1):\n",
    "    N = int(i) #Number of RBF's\n",
    "    mu = np.linspace(0,2*np.pi,N) # Data is one-dimensional\n",
    "    sigma = np.pi/i*np.ones(N) # Smaller sigma when many RBF's\n",
    "    \n",
    "    w = lab2.least_squares(x_train,yf1_train,mu,sigma)\n",
    "    yf1_pred = lab2.forward(x_valid,w,mu,sigma)\n",
    "    are_sin[N-2] = np.mean(np.abs(yf1_pred-yf1_valid))\n",
    "\n",
    "    w = lab2.least_squares(x_train,yf2_train,mu,sigma)\n",
    "    yf2_pred = lab2.forward(x_valid,w,mu,sigma)\n",
    "    are_square[N-2] = np.mean(np.abs(yf2_pred-yf2_valid))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(visible = True)\n",
    "ax.set_title('Absolute residual error vs #RBF`s')\n",
    "ax.plot(np.linspace(2,maxN,maxN-1),are_sin)\n",
    "ax.plot(np.linspace(2,maxN,maxN-1),are_square)\n",
    "ax.set_xlabel('number of RBF`s')\n",
    "ax.set_ylabel('mean absolute error')\n",
    "ax.legend(['sin(2x)','square(2x)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Regression with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5087160ba4cde6d3d9644b815025c2e683db921b7915469398fa6a2e285f70d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
